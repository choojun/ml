{"cells":[{"cell_type":"markdown","metadata":{"id":"Sw_iZPOIBrIF"},"source":["## Transfer Learning using MNIST data\n","To illustrate the power and concept of transfer learning, we will train a CNN on just the digits 5,6,7,8,9.  Then we will train just the last layer(s) of the network on the digits 0,1,2,3,4 and see how well the features learned on 5-9 help with classifying 0-4.\n","\n","Adapted from https://github.com/fchollet/keras/blob/master/examples/mnist_transfer_cnn.py"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"ML_dlDklBrIK","executionInfo":{"status":"ok","timestamp":1747095909413,"user_tz":-480,"elapsed":10493,"user":{"displayName":"CHOO JUN TAN","userId":"08239778815350167935"}}},"outputs":[],"source":["from __future__ import print_function\n","\n","import datetime\n","import keras\n","from keras.datasets import mnist\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Activation, Flatten\n","from keras.layers import Conv2D, MaxPooling2D\n","from keras import backend as K"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"J_uxtm6ABrIM","executionInfo":{"status":"ok","timestamp":1747095912800,"user_tz":-480,"elapsed":5,"user":{"displayName":"CHOO JUN TAN","userId":"08239778815350167935"}}},"outputs":[],"source":["#used to help some of the timing functions\n","now = datetime.datetime.now"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"7M6OvXP6BrIN","executionInfo":{"status":"ok","timestamp":1747095914309,"user_tz":-480,"elapsed":14,"user":{"displayName":"CHOO JUN TAN","userId":"08239778815350167935"}}},"outputs":[],"source":["# set some parameters\n","batch_size = 128\n","num_classes = 5\n","epochs = 5"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"Gm3Gn4QYBrIO","executionInfo":{"status":"ok","timestamp":1747095916476,"user_tz":-480,"elapsed":10,"user":{"displayName":"CHOO JUN TAN","userId":"08239778815350167935"}}},"outputs":[],"source":["# set some more parameters\n","img_rows, img_cols = 28, 28\n","filters = 32\n","pool_size = 2\n","kernel_size = 3"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"AOBWjfTYBrIO","executionInfo":{"status":"ok","timestamp":1747095918918,"user_tz":-480,"elapsed":9,"user":{"displayName":"CHOO JUN TAN","userId":"08239778815350167935"}}},"outputs":[],"source":["## This just handles some variability in how the input data is loaded\n","\n","if K.image_data_format() == 'channels_first':\n","    input_shape = (1, img_rows, img_cols)\n","else:\n","    input_shape = (img_rows, img_cols, 1)"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"bY-DmndaBrIO","executionInfo":{"status":"ok","timestamp":1747095919916,"user_tz":-480,"elapsed":3,"user":{"displayName":"CHOO JUN TAN","userId":"08239778815350167935"}}},"outputs":[],"source":["## To simplify things, write a function to include all the training steps\n","## As input, function takes a model, training set, test set, and the number of classes\n","## Inside the model object will be the state about which layers we are freezing and which we are training\n","\n","def train_model(model, train, test, num_classes):\n","    x_train = train[0].reshape((train[0].shape[0],) + input_shape)\n","    x_test = test[0].reshape((test[0].shape[0],) + input_shape)\n","    x_train = x_train.astype('float32')\n","    x_test = x_test.astype('float32')\n","    x_train /= 255\n","    x_test /= 255\n","    print('x_train shape:', x_train.shape)\n","    print(x_train.shape[0], 'train samples')\n","    print(x_test.shape[0], 'test samples')\n","\n","    # convert class vectors to binary class matrices\n","    y_train = keras.utils.to_categorical(train[1], num_classes)\n","    y_test = keras.utils.to_categorical(test[1], num_classes)\n","\n","    model.compile(loss='categorical_crossentropy',\n","                  optimizer='adadelta',\n","                  metrics=['accuracy'])\n","\n","    t = now()\n","    model.fit(x_train, y_train,\n","              batch_size=batch_size,\n","              epochs=epochs,\n","              verbose=1,\n","              validation_data=(x_test, y_test))\n","    print('Training time: %s' % (now() - t))\n","\n","    score = model.evaluate(x_test, y_test, verbose=0)\n","    print('Test score:', score[0])\n","    print('Test accuracy:', score[1])"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"VwnGMOo1BrIP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1747095923488,"user_tz":-480,"elapsed":481,"user":{"displayName":"CHOO JUN TAN","userId":"08239778815350167935"}},"outputId":"d816bd44-5636-4296-a851-b4f2a9abb308"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"]}],"source":["# the data, shuffled and split between train and test sets\n","(x_train, y_train), (x_test, y_test) = mnist.load_data()\n","\n","# create two datasets: one with digits below 5 and one with 5 and above\n","x_train_lt5 = x_train[y_train < 5]\n","y_train_lt5 = y_train[y_train < 5]\n","x_test_lt5 = x_test[y_test < 5]\n","y_test_lt5 = y_test[y_test < 5]\n","\n","x_train_gte5 = x_train[y_train >= 5]\n","y_train_gte5 = y_train[y_train >= 5] - 5\n","x_test_gte5 = x_test[y_test >= 5]\n","y_test_gte5 = y_test[y_test >= 5] - 5"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"JYSOW18aBrIP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1747095926297,"user_tz":-480,"elapsed":53,"user":{"displayName":"CHOO JUN TAN","userId":"08239778815350167935"}},"outputId":"baada609-b1ab-4594-8272-42c0b1b3e13a"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]}],"source":["# Define the \"feature\" layers.  These are the early layers that we expect will \"transfer\"\n","# to a new problem.  We will freeze these layers during the fine-tuning process\n","\n","feature_layers = [\n","    Conv2D(filters, kernel_size,\n","           padding='valid',\n","           input_shape=input_shape),\n","    Activation('relu'),\n","    Conv2D(filters, kernel_size),\n","    Activation('relu'),\n","    MaxPooling2D(pool_size=pool_size),\n","    Dropout(0.25),\n","    Flatten(),\n","]"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"Oftzv0-TBrIQ","executionInfo":{"status":"ok","timestamp":1747095929900,"user_tz":-480,"elapsed":16,"user":{"displayName":"CHOO JUN TAN","userId":"08239778815350167935"}}},"outputs":[],"source":["# Define the \"classification\" layers.  These are the later layers that predict the specific classes from the features\n","# learned by the feature layers.  This is the part of the model that needs to be re-trained for a new problem\n","\n","classification_layers = [\n","    Dense(128),\n","    Activation('relu'),\n","    Dropout(0.5),\n","    Dense(num_classes),\n","    Activation('softmax')\n","]"]},{"cell_type":"code","execution_count":10,"metadata":{"collapsed":true,"id":"heGKVhJyBrIQ","executionInfo":{"status":"ok","timestamp":1747095932291,"user_tz":-480,"elapsed":44,"user":{"displayName":"CHOO JUN TAN","userId":"08239778815350167935"}}},"outputs":[],"source":["# We create our model by combining the two sets of layers as follows\n","model = Sequential(feature_layers + classification_layers)"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"-eYWfe_CBrIQ","outputId":"064c43a0-d4ef-425a-a0fb-0fb10b9151ae","colab":{"base_uri":"https://localhost:8080/","height":529},"executionInfo":{"status":"ok","timestamp":1747095933602,"user_tz":-480,"elapsed":208,"user":{"displayName":"CHOO JUN TAN","userId":"08239778815350167935"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["\u001b[1mModel: \"sequential\"\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n","│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m320\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ activation (\u001b[38;5;33mActivation\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │         \u001b[38;5;34m9,248\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ activation_1 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4608\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m589,952\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ activation_2 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │           \u001b[38;5;34m645\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ activation_3 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n","└─────────────────────────────────┴────────────────────────┴───────────────┘\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n","│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ activation (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ activation_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4608</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">589,952</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ activation_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">645</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ activation_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","└─────────────────────────────────┴────────────────────────┴───────────────┘\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m600,165\u001b[0m (2.29 MB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">600,165</span> (2.29 MB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m600,165\u001b[0m (2.29 MB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">600,165</span> (2.29 MB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"]},"metadata":{}}],"source":["# Let's take a look\n","model.summary()"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"hwBw9iGgBrIR","outputId":"d30624e7-3aa6-42a6-d8fd-03f2f674c96b","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1747096282128,"user_tz":-480,"elapsed":345054,"user":{"displayName":"CHOO JUN TAN","userId":"08239778815350167935"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["x_train shape: (29404, 28, 28, 1)\n","29404 train samples\n","4861 test samples\n","Epoch 1/5\n","\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 213ms/step - accuracy: 0.2030 - loss: 1.6168 - val_accuracy: 0.2107 - val_loss: 1.6023\n","Epoch 2/5\n","\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 195ms/step - accuracy: 0.2424 - loss: 1.5995 - val_accuracy: 0.2822 - val_loss: 1.5828\n","Epoch 3/5\n","\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 197ms/step - accuracy: 0.2912 - loss: 1.5836 - val_accuracy: 0.4717 - val_loss: 1.5622\n","Epoch 4/5\n","\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 203ms/step - accuracy: 0.3635 - loss: 1.5612 - val_accuracy: 0.6143 - val_loss: 1.5393\n","Epoch 5/5\n","\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 197ms/step - accuracy: 0.4240 - loss: 1.5411 - val_accuracy: 0.6832 - val_loss: 1.5132\n","Training time: 0:05:42.211266\n","Test score: 1.5132181644439697\n","Test accuracy: 0.6831927299499512\n"]}],"source":["# Now, let's train our model on the digits 5,6,7,8,9\n","\n","train_model(model,\n","            (x_train_gte5, y_train_gte5),\n","            (x_test_gte5, y_test_gte5), num_classes)"]},{"cell_type":"markdown","metadata":{"id":"wnOQNSGCBrIR"},"source":["### Freezing Layers\n","Keras allows layers to be \"frozen\" during the training process.  That is, some layers would have their weights updated during the training process, while others would not.  This is a core part of transfer learning, the ability to train just the last one or several layers.\n","\n","Note also, that a lot of the training time is spent \"back-propagating\" the gradients back to the first layer.  Therefore, if we only need to compute the gradients back a small number of layers, the training time is much quicker per iteration.  This is in addition to the savings gained by being able to train on a smaller data set."]},{"cell_type":"code","execution_count":13,"metadata":{"collapsed":true,"id":"MLVevOg9BrIR","executionInfo":{"status":"ok","timestamp":1747096314314,"user_tz":-480,"elapsed":73,"user":{"displayName":"CHOO JUN TAN","userId":"08239778815350167935"}}},"outputs":[],"source":["# Freeze only the\n","for l in feature_layers:\n","    l.trainable = False"]},{"cell_type":"markdown","metadata":{"id":"ZcDgLlIaBrIR"},"source":["Observe below the differences between the number of *total params*, *trainable params*, and *non-trainable params*."]},{"cell_type":"code","execution_count":14,"metadata":{"id":"qoxknPVjBrIR","outputId":"56a255d7-d48e-4238-b564-665a26d73223","colab":{"base_uri":"https://localhost:8080/","height":545},"executionInfo":{"status":"ok","timestamp":1747096317318,"user_tz":-480,"elapsed":324,"user":{"displayName":"CHOO JUN TAN","userId":"08239778815350167935"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["\u001b[1mModel: \"sequential\"\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n","│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m320\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ activation (\u001b[38;5;33mActivation\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │         \u001b[38;5;34m9,248\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ activation_1 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4608\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m589,952\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ activation_2 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │           \u001b[38;5;34m645\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ activation_3 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n","└─────────────────────────────────┴────────────────────────┴───────────────┘\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n","│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ activation (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ activation_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4608</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">589,952</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ activation_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">645</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ activation_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","└─────────────────────────────────┴────────────────────────┴───────────────┘\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,800,497\u001b[0m (6.87 MB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,800,497</span> (6.87 MB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m590,597\u001b[0m (2.25 MB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">590,597</span> (2.25 MB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m9,568\u001b[0m (37.38 KB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,568</span> (37.38 KB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m1,200,332\u001b[0m (4.58 MB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,200,332</span> (4.58 MB)\n","</pre>\n"]},"metadata":{}}],"source":["model.summary()"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"TPigfgh2BrIR","outputId":"b0c286a7-8f54-4f88-d262-5c894e6d1fee","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1747096423749,"user_tz":-480,"elapsed":103337,"user":{"displayName":"CHOO JUN TAN","userId":"08239778815350167935"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["x_train shape: (30596, 28, 28, 1)\n","30596 train samples\n","5139 test samples\n","Epoch 1/5\n","\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 75ms/step - accuracy: 0.1968 - loss: 1.6034 - val_accuracy: 0.3734 - val_loss: 1.5716\n","Epoch 2/5\n","\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 74ms/step - accuracy: 0.2892 - loss: 1.5742 - val_accuracy: 0.4933 - val_loss: 1.5416\n","Epoch 3/5\n","\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 73ms/step - accuracy: 0.3711 - loss: 1.5469 - val_accuracy: 0.5672 - val_loss: 1.5111\n","Epoch 4/5\n","\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 68ms/step - accuracy: 0.4402 - loss: 1.5181 - val_accuracy: 0.6495 - val_loss: 1.4795\n","Epoch 5/5\n","\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 74ms/step - accuracy: 0.5152 - loss: 1.4874 - val_accuracy: 0.7266 - val_loss: 1.4476\n","Training time: 0:01:41.015497\n","Test score: 1.4475958347320557\n","Test accuracy: 0.7266005277633667\n"]}],"source":["train_model(model,\n","            (x_train_lt5, y_train_lt5),\n","            (x_test_lt5, y_test_lt5), num_classes)"]},{"cell_type":"markdown","metadata":{"id":"43j38I90BrIS"},"source":["Note that after a single epoch, we are already achieving results on classifying 0-4 that are comparable to those achieved on 5-9 after 5 full epochs.  This despite the fact the we are only \"fine-tuning\" the last layer of the network, and all the early layers have never seen what the digits 0-4 look like.\n","\n","Also, note that even though nearly all (590K/600K) of the *parameters* were trainable, the training time per epoch was still much reduced.  This is because the unfrozen part of the network was very shallow, making backpropagation faster."]},{"cell_type":"markdown","metadata":{"id":"VgM61e34BrIS"},"source":["## Exercise\n","### To do:\n","- Now write code to reverse this training process.  That is, you will train on the digits 0-4, and then finetune only the last layers on the digits 5-9."]},{"cell_type":"code","execution_count":16,"metadata":{"id":"BefmJKOsBrIS","executionInfo":{"status":"ok","timestamp":1747096434650,"user_tz":-480,"elapsed":4,"user":{"displayName":"CHOO JUN TAN","userId":"08239778815350167935"}}},"outputs":[],"source":["# We create our model by combining the two sets of layers as follows\n","model_2 = Sequential(feature_layers + classification_layers)"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"s0y5NLB_BrIS","outputId":"86e9e021-6d5f-4ab0-be73-93a60df6c48a","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1747096541429,"user_tz":-480,"elapsed":104854,"user":{"displayName":"CHOO JUN TAN","userId":"08239778815350167935"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["x_train shape: (30596, 28, 28, 1)\n","30596 train samples\n","5139 test samples\n","Epoch 1/5\n","\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 77ms/step - accuracy: 0.5583 - loss: 1.4595 - val_accuracy: 0.7708 - val_loss: 1.4164\n","Epoch 2/5\n","\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 69ms/step - accuracy: 0.6031 - loss: 1.4282 - val_accuracy: 0.8112 - val_loss: 1.3846\n","Epoch 3/5\n","\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 73ms/step - accuracy: 0.6443 - loss: 1.4008 - val_accuracy: 0.8362 - val_loss: 1.3532\n","Epoch 4/5\n","\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 73ms/step - accuracy: 0.6830 - loss: 1.3696 - val_accuracy: 0.8543 - val_loss: 1.3217\n","Epoch 5/5\n","\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 76ms/step - accuracy: 0.7073 - loss: 1.3420 - val_accuracy: 0.8648 - val_loss: 1.2906\n","Training time: 0:01:41.711970\n","Test score: 1.2905715703964233\n","Test accuracy: 0.8647596836090088\n"]}],"source":["train_model(model_2,\n","            (x_train_lt5, y_train_lt5),\n","            (x_test_lt5, y_test_lt5), num_classes)"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"lSI1ibQrBrIS","executionInfo":{"status":"ok","timestamp":1747096568508,"user_tz":-480,"elapsed":1,"user":{"displayName":"CHOO JUN TAN","userId":"08239778815350167935"}}},"outputs":[],"source":["# Freeze only the\n","for l in feature_layers:\n","    l.trainable = False"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"GXINTH3qBrIS","outputId":"25c9bb39-b496-4859-a4f2-474283fe81ce","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1747096665768,"user_tz":-480,"elapsed":96168,"user":{"displayName":"CHOO JUN TAN","userId":"08239778815350167935"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["x_train shape: (29404, 28, 28, 1)\n","29404 train samples\n","4861 test samples\n","Epoch 1/5\n","\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 75ms/step - accuracy: 0.4402 - loss: 1.4972 - val_accuracy: 0.5639 - val_loss: 1.4621\n","Epoch 2/5\n","\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 76ms/step - accuracy: 0.4828 - loss: 1.4685 - val_accuracy: 0.6050 - val_loss: 1.4350\n","Epoch 3/5\n","\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 75ms/step - accuracy: 0.5085 - loss: 1.4464 - val_accuracy: 0.6453 - val_loss: 1.4084\n","Epoch 4/5\n","\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 75ms/step - accuracy: 0.5498 - loss: 1.4201 - val_accuracy: 0.6822 - val_loss: 1.3823\n","Epoch 5/5\n","\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 76ms/step - accuracy: 0.5784 - loss: 1.3976 - val_accuracy: 0.7157 - val_loss: 1.3568\n","Training time: 0:01:34.208558\n","Test score: 1.356813907623291\n","Test accuracy: 0.7156963348388672\n"]}],"source":["train_model(model_2,\n","            (x_train_gte5, y_train_gte5),\n","            (x_test_gte5, y_test_gte5), num_classes)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}
