{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xyOG0CAcoX_n",
        "outputId": "85152479-f0ba-44de-c92a-a6736ca95695"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gymnasium in /usr/local/lib/python3.12/dist-packages (1.2.3)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium) (2.0.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium) (3.1.2)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium) (4.15.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from gymnasium) (0.0.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install gymnasium\n",
        "import gymnasium as gym\n",
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GymEnvironment:\n",
        "    def __init__(self, env_name=\"CartPole-v1\"):\n",
        "        self.env = gym.make(env_name)\n",
        "        self.state, self.info = self.env.reset()\n",
        "        self.name = env_name\n",
        "        print(f\"Environment'{env_name}' initialized.\")\n",
        "\n",
        "    def do(self, action):\n",
        "        next_state,reward, terminated, truncated, info = self.env.step(action)\n",
        "        done = terminated or truncated\n",
        "        self.state = next_state\n",
        "        return reward, next_state, done, info"
      ],
      "metadata": {
        "id": "k5T92REiooiy"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_custom_env_instance = GymEnvironment(env_name=\"CartPole-v1\")\n",
        "\n",
        "action = my_custom_env_instance.env.action_space.sample()\n",
        "\n",
        "reward, next_state, done, info = my_custom_env_instance.do(action)\n",
        "print(f\"Action: {action}, Reward: {reward}, Done: {done}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xdxsVXZ3ot_i",
        "outputId": "f531f5c6-fa2d-481d-f24c-2d693c68590f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Environment'CartPole-v1' initialized.\n",
            "Action: 1, Reward: 1.0, Done: False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class RLAgent:\n",
        "    def __init__(self, actions):\n",
        "        self.actions = actions\n",
        "        self.state = None\n",
        "        self.reward = 0\n",
        "        self.action = None\n",
        "        self.name = \"Random Agent\"\n",
        "\n",
        "    def select_action(self, env_state):\n",
        "        self.state = env_state\n",
        "        self.action = random.choice(self.actions)\n",
        "        return self.action\n",
        "\n",
        "    def v(self, state):\n",
        "        return 0\n",
        "\n",
        "    def q(self, action):\n",
        "        return 0"
      ],
      "metadata": {
        "id": "A6Cc_z_0pEvR"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env = GymEnvironment(env_name=\"CartPole-v1\")\n",
        "agent = RLAgent(actions = list(range(env.env.action_space.n)))\n",
        "\n",
        "state = env.state\n",
        "action = agent.select_action(state)\n",
        "reward, next_state, done, info = env.do(action)\n",
        "print(f\"Initial action: {action}, Reward: {reward}\")\n",
        "\n",
        "next_action = agent.select_action(next_state)\n",
        "print(f\"Next action: {next_action}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aI_ubXzYpPDR",
        "outputId": "a48b835a-e27c-4f67-e242-629a281bfced"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Environment'CartPole-v1' initialized.\n",
            "Initial action: 0, Reward: 1.0\n",
            "Next action: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Simulation:\n",
        "    def __init__(self, agent, envionment):\n",
        "        self.agent = agent\n",
        "        self.env = envionment\n",
        "        self.reward_history = []\n",
        "        self.total_reward = 0\n",
        "        self.steps = 0\n",
        "        self.action = None\n",
        "\n",
        "    def start(self):\n",
        "        self.action = self.agent.select_action(self.env.state)\n",
        "        return self\n",
        "\n",
        "    def go(self, n=10):\n",
        "        for i in range(n):\n",
        "            reward, next_state, done, info = self.env.do(self.action)\n",
        "            self.reward_history.append(reward)\n",
        "            self.total_reward += reward\n",
        "            self.steps += 1\n",
        "            if done:\n",
        "                # Reset the environment and update the agent's perception of the state\n",
        "                self.env.state, self.env.info = self.env.env.reset()\n",
        "\n",
        "            # Select the next action based on the current environment state (which might have been reset)\n",
        "            self.action = self.agent.select_action(self.env.state)\n",
        "        print(f\"Total reward after {n} steps: {self.total_reward}\")\n",
        "        return self"
      ],
      "metadata": {
        "id": "g0Y_Lj6XpU2E"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env = GymEnvironment(env_name=\"CartPole-v1\")\n",
        "agent = RLAgent(actions=list(range(env.env.action_space.n)))\n",
        "sim = Simulation(agent, env)\n",
        "sim.start().go(100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m9xHt72NpUsr",
        "outputId": "398c62a1-567b-427d-ecb7-f95d69ccd0de"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Environment'CartPole-v1' initialized.\n",
            "Total reward after 100 steps: 100.0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<__main__.Simulation at 0x79931a210320>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    }
  ]
}