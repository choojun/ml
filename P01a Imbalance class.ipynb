{"cells":[{"cell_type":"markdown","metadata":{"id":"67ySuxsSfula"},"source":["## Imbalance class"],"id":"67ySuxsSfula"},{"cell_type":"code","execution_count":null,"metadata":{"id":"-zn3UrJlfule"},"outputs":[],"source":["# Importing necessary libraries\n","import numpy as np\n","import pandas as pd"],"id":"-zn3UrJlfule"},{"cell_type":"code","execution_count":null,"metadata":{"id":"3sF56PABfulg"},"outputs":[],"source":["# https://www.kaggle.com/datasets/uciml/breast-cancer-wisconsin-data?resource=download\n","\n","df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data', header=None)"],"id":"3sF56PABfulg"},{"cell_type":"code","execution_count":null,"metadata":{"id":"R6qzOpOwfulh"},"outputs":[],"source":["# selects all rows and columns from the third column (indicating the features) and converting to a numpy array.\n","# selects all rows of the second column (ndicating the target variable) and converting to a numpy array\n","\n","X = df.loc[:, 2:].values\n","y = df.loc[:, 1].values\n","\n","# X matrix has dimensions (n_samples, n_features) and y is a 1-dimensional vector of length n_samples."],"id":"R6qzOpOwfulh"},{"cell_type":"code","execution_count":null,"metadata":{"id":"Or2OuGlzfuli","outputId":"8c453bb7-0013-448a-e53f-44b281c0e502"},"outputs":[{"data":{"text/plain":["array([[1.799e+01, 1.038e+01, 1.228e+02, 1.001e+03, 1.184e-01, 2.776e-01,\n","        3.001e-01, 1.471e-01, 2.419e-01, 7.871e-02, 1.095e+00, 9.053e-01,\n","        8.589e+00, 1.534e+02, 6.399e-03, 4.904e-02, 5.373e-02, 1.587e-02,\n","        3.003e-02, 6.193e-03, 2.538e+01, 1.733e+01, 1.846e+02, 2.019e+03,\n","        1.622e-01, 6.656e-01, 7.119e-01, 2.654e-01, 4.601e-01, 1.189e-01],\n","       [2.057e+01, 1.777e+01, 1.329e+02, 1.326e+03, 8.474e-02, 7.864e-02,\n","        8.690e-02, 7.017e-02, 1.812e-01, 5.667e-02, 5.435e-01, 7.339e-01,\n","        3.398e+00, 7.408e+01, 5.225e-03, 1.308e-02, 1.860e-02, 1.340e-02,\n","        1.389e-02, 3.532e-03, 2.499e+01, 2.341e+01, 1.588e+02, 1.956e+03,\n","        1.238e-01, 1.866e-01, 2.416e-01, 1.860e-01, 2.750e-01, 8.902e-02],\n","       [1.969e+01, 2.125e+01, 1.300e+02, 1.203e+03, 1.096e-01, 1.599e-01,\n","        1.974e-01, 1.279e-01, 2.069e-01, 5.999e-02, 7.456e-01, 7.869e-01,\n","        4.585e+00, 9.403e+01, 6.150e-03, 4.006e-02, 3.832e-02, 2.058e-02,\n","        2.250e-02, 4.571e-03, 2.357e+01, 2.553e+01, 1.525e+02, 1.709e+03,\n","        1.444e-01, 4.245e-01, 4.504e-01, 2.430e-01, 3.613e-01, 8.758e-02],\n","       [1.142e+01, 2.038e+01, 7.758e+01, 3.861e+02, 1.425e-01, 2.839e-01,\n","        2.414e-01, 1.052e-01, 2.597e-01, 9.744e-02, 4.956e-01, 1.156e+00,\n","        3.445e+00, 2.723e+01, 9.110e-03, 7.458e-02, 5.661e-02, 1.867e-02,\n","        5.963e-02, 9.208e-03, 1.491e+01, 2.650e+01, 9.887e+01, 5.677e+02,\n","        2.098e-01, 8.663e-01, 6.869e-01, 2.575e-01, 6.638e-01, 1.730e-01],\n","       [2.029e+01, 1.434e+01, 1.351e+02, 1.297e+03, 1.003e-01, 1.328e-01,\n","        1.980e-01, 1.043e-01, 1.809e-01, 5.883e-02, 7.572e-01, 7.813e-01,\n","        5.438e+00, 9.444e+01, 1.149e-02, 2.461e-02, 5.688e-02, 1.885e-02,\n","        1.756e-02, 5.115e-03, 2.254e+01, 1.667e+01, 1.522e+02, 1.575e+03,\n","        1.374e-01, 2.050e-01, 4.000e-01, 1.625e-01, 2.364e-01, 7.678e-02]])"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["# select the first five rows of the 'X' array\n","\n","X[:5]"],"id":"Or2OuGlzfuli"},{"cell_type":"code","execution_count":null,"metadata":{"id":"7LvEmC_rfuli","outputId":"ce9bc827-f355-4b78-b30f-6a54321dd660"},"outputs":[{"data":{"text/plain":["array(['M', 'M', 'M', 'M', 'M'], dtype=object)"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["# slice the first five elements from the y array\n","\n","y[:5]"],"id":"7LvEmC_rfuli"},{"cell_type":"code","execution_count":null,"metadata":{"id":"poi0_nc4fulj","outputId":"85d17f48-d943-4da0-c6ab-6c3eec2ececb"},"outputs":[{"data":{"text/plain":["array(['B', 'M'], dtype=object)"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["'''\n","Importing the LabelEncoder class from the sklearn.preprocessing module\n","Creating an instance of the LabelEncoder class and fitting it to the target variable y\n","Printing the unique classes in the target variable\n","'''\n","from sklearn.preprocessing import LabelEncoder\n","le = LabelEncoder()\n","y = le.fit_transform(y)\n","le.classes_"],"id":"poi0_nc4fulj"},{"cell_type":"markdown","metadata":{"id":"Pr83olKnfulk"},"source":["- Creating a new array X_imb by stacking vertically X elements where y equals 0 and X elements where y equals 1 up to the 40th element.\n","- This results in a new X_imb array that is imbalanced, with many more examples where y is 0 than where y is 1.\n","- Creating a new array y_imb by concatenating horizontally y elements where y equals 0 and y elements where y equals 1 up to the 40th element.\n","- This results in a new y_imb array that is imbalanced, with many more examples where y is 0 than where y is 1."],"id":"Pr83olKnfulk"},{"cell_type":"code","execution_count":null,"metadata":{"id":"mOMHLusqfulk"},"outputs":[],"source":["X_imb = np.vstack((X[y == 0], X[y == 1][:40]))\n","y_imb = np.hstack((y[y == 0], y[y == 1][:40]))"],"id":"mOMHLusqfulk"},{"cell_type":"markdown","metadata":{"id":"ickfVc_Ffulk"},"source":["- originally consisted of 357 benign tumors (class 0) and 212 malignant tumors (class 1)\n","- took all 357 benign tumor samples and stacked them with the first 40 malignant samples to create a stark class imbalance\n","-  to compute the accuracy of a model that always predicts the majority class (benign, class 0), we would achieve a prediction accuracy of approximately 90 percent:"],"id":"ickfVc_Ffulk"},{"cell_type":"code","execution_count":null,"metadata":{"id":"-vstholzfulk","outputId":"3aefbc2f-5225-4b6d-b682-d21206c1e95f"},"outputs":[{"data":{"text/plain":["89.92443324937027"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["# creates a numpy array with zeros of shape y_imb.shape[0] and assigns it to y_pred.\n","y_pred = np.zeros(y_imb.shape[0])\n","\n","# computes the mean accuracy of y_pred compared to y_imb. It multiplies the boolean array resulting from the comparison by 100 and returns the result as a percentage.\n","np.mean(y_pred == y_imb) * 100"],"id":"-vstholzfulk"},{"cell_type":"code","execution_count":null,"metadata":{"id":"SD6v0Yh8full"},"outputs":[],"source":["# resampling data involves randomly drawing samples from a dataset with replacement to create a new dataset with a different distribution of values.\n","from sklearn.utils import resample"],"id":"SD6v0Yh8full"},{"cell_type":"code","execution_count":null,"metadata":{"id":"4VY0A0QGfull","outputId":"95ea33ed-27cf-49aa-d173-3b3feb7f8830"},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of class 1 samples before: 40\n"]}],"source":["print('Number of class 1 samples before:', X_imb[y_imb == 1].shape[0])"],"id":"4VY0A0QGfull"},{"cell_type":"markdown","metadata":{"id":"ItaHT44Nfull"},"source":["- dealing with highly unbalanced datasets is called resampling\n","- consists of\n","    - removing samples from the majority class (under-sampling)\n","        - randomly removing observations from the majority class to prevent its signal from dominating the learning algorithm. The most common heuristic for doing so is resampling without replacement\n","        - First, separate observations from each class into different datasets.\n","        - Next, resample the majority class without replacement, setting the number of samples to match that of the minority class.\n","        - Finally, combine the down-sampled majority class dataset with the original minority class dataset.\n","    - adding more examples from the minority class (over-sampling or up-sampling) - can cause overfitting\n","        - First separate observations from each class into different datasets.\n","        - Next, resample the minority class with replacement, setting the number of samples to match that of the majority class.\n","        - Finally, combine the up-sampled minority class dataset with the original majority class dataset.\n","\n","![image.png](attachment:image.png)"],"id":"ItaHT44Nfull"},{"cell_type":"markdown","metadata":{"id":"_fxkwJx6fulm"},"source":["## Oversampling"],"id":"_fxkwJx6fulm"},{"cell_type":"code","execution_count":null,"metadata":{"id":"apF0Iq-xfulm"},"outputs":[],"source":["#  resamples the minority class (y_imb == 1) with replacement to have the same number of samples as the majority class (y_imb == 0).\n","\n","X_upsampled, y_upsampled = resample(X_imb[y_imb == 1], y_imb[y_imb == 1],\n","                                    replace=True, #sample with replacement\n","                                    n_samples=X_imb[y_imb == 0].shape[0], # to match majority class\n","                                    random_state=123)"],"id":"apF0Iq-xfulm"},{"cell_type":"code","execution_count":null,"metadata":{"id":"ADhhAhRlfulm"},"outputs":[],"source":["# prints the number of samples after upsampling the minority class.\n","\n","print('Number of class 1 samples after:', X_upsampled.shape[0])"],"id":"ADhhAhRlfulm"},{"cell_type":"code","execution_count":null,"metadata":{"id":"76_DcZWFfulm"},"outputs":[],"source":["# concatenate the upsampled minority class with the original majority class.\n","\n","X_bal = np.vstack((X[y == 0], X_upsampled))\n","y_bal = np.hstack((y[y == 0], y_upsampled))"],"id":"76_DcZWFfulm"},{"cell_type":"code","execution_count":null,"metadata":{"id":"5dEQZh_Yfulm"},"outputs":[],"source":["# initializes y_pred to an array of zeros with the length equal to the number of samples in the concatenated dataset (y_bal).\n","# Then it calculates the percentage of correct predictions by comparing y_pred and y_bal.\n","y_pred = np.zeros(y_bal.shape[0])\n","np.mean(y_pred == y_bal) * 100"],"id":"5dEQZh_Yfulm"},{"cell_type":"markdown","metadata":{"id":"U9aD3YQkfulm"},"source":["## Undersampling"],"id":"U9aD3YQkfulm"},{"cell_type":"code","execution_count":null,"metadata":{"id":"WnI4F2X2fulm"},"outputs":[],"source":["# This code initializes an array of zeros named 'y_pred' with the same shape as the input array 'y_imb'.\n","# The mean of the comparison between 'y_pred' and 'y_imb' is calculated and multiplied by 100. This gives the percentage of times 'y_pred' is equal to 'y_imb'.\n","\n","y_pred = np.zeros(y_imb.shape[0])\n","np.mean(y_pred == y_imb) * 100"],"id":"WnI4F2X2fulm"},{"cell_type":"code","execution_count":null,"metadata":{"id":"1PplkStjfulm"},"outputs":[],"source":["X_downsampled, y_downsampled = resample(X_imb[y_imb == 0], y_imb[y_imb == 0],\n","                                    replace=False, #sample without replacement\n","                                    n_samples=X_imb[y_imb == 1].shape[0], # to match minority class\n","                                    random_state=123)"],"id":"1PplkStjfulm"},{"cell_type":"code","execution_count":null,"metadata":{"id":"XpYdupZXfuln"},"outputs":[],"source":["print('Number of class 0 samples after:', X_downsampled.shape[0])"],"id":"XpYdupZXfuln"},{"cell_type":"code","execution_count":null,"metadata":{"id":"gceqpmp8fuln"},"outputs":[],"source":["X_bal2 = np.vstack((X[y == 1][:40], X_downsampled))\n","y_bal2 = np.hstack((y[y == 1][:40], y_downsampled))"],"id":"gceqpmp8fuln"},{"cell_type":"code","execution_count":null,"metadata":{"id":"PZCOu-3qfuln"},"outputs":[],"source":["y_bal2"],"id":"PZCOu-3qfuln"},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZHRQR9Myfuln"},"outputs":[],"source":["y_pred = np.zeros(y_bal2.shape[0])\n","np.mean(y_pred == y_bal2) * 100"],"id":"ZHRQR9Myfuln"},{"cell_type":"markdown","metadata":{"id":"8jFXJwjYfuln"},"source":["# Exercise"],"id":"8jFXJwjYfuln"},{"cell_type":"code","execution_count":null,"metadata":{"id":"l3dT1YPQfuln"},"outputs":[],"source":["from sklearn.datasets import load_breast_cancer\n","from sklearn.utils import resample\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score\n","\n","# Load the breast cancer wisconsin dataset\n","data = load_breast_cancer()\n","\n","# Split the data into features and labels\n","X, y = data.data, data.target\n","\n","# Create an imbalanced dataset by randomly sampling 100 instances from the majority class (label 0) and keeping all instances from the minority class (label 1)\n","X_imb = np.vstack((X[y == 0][:100], X[y == 1]))\n","y_imb = np.hstack((y[y == 0][:100], y[y == 1]))\n","\n","# Upsample the minority class to match the number of instances in the majority class\n","X_bal, y_bal = resample(X_imb[y_imb == 1], y_imb[y_imb == 1], replace=True, n_samples=X_imb[y_imb == 0].shape[0], random_state=123)\n","\n","# Split the data into training and testing sets using a 70/30 split\n","X_train, X_test, y_train, y_test = train_test_split(X_bal, y_bal, test_size=0.3, random_state=123)\n","\n","# Train a logistic regression model on the balanced data and test it on the testing set\n","clf_bal = LogisticRegression(random_state=123)\n","clf_bal.fit(X_train, y_train)\n","y_pred_bal = clf_bal.predict(X_test)\n","\n","# Compare the results to a logistic regression model trained on the imbalanced data and tested on the same testing set\n","clf_imb = LogisticRegression(random_state=123)\n","clf_imb.fit(X_imb, y_imb)\n","y_pred_imb = clf_imb.predict(X_test)\n","\n","# Print the accuracy scores\n","print(\"Accuracy score (balanced data):\", accuracy_score(y_test, y_pred_bal))\n","print(\"Accuracy score (imbalanced data):\", accuracy_score(y_test, y_pred_imb))\n"],"id":"l3dT1YPQfuln"},{"cell_type":"code","execution_count":null,"metadata":{"id":"KyC-XbdNfuln"},"outputs":[],"source":[],"id":"KyC-XbdNfuln"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}